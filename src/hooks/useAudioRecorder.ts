import { useState, useRef, useCallback } from "react";

export interface AudioRecorderState {
  isRecording: boolean;
  recordingTime: number;
  audioBlob: Blob | null;
}

type UseVoiceInputOptions = {
  // how to insert the transcribed text into this input
  appendText: (text: string) => void;
  // optional error handler (e.g. setError in ChatInput)
  onError?: (message: string) => void;
};

export function useAudioRecorder(onRecordingComplete?: (blob: Blob) => void) {
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // Setup Audio Context for visualization
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);

      analyserRef.current = analyser;
      audioContextRef.current = audioContext;

      const mediaRecorder = new MediaRecorder(stream);

      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: "audio/webm" });
        setAudioBlob(blob);
        if (onRecordingComplete) {
          onRecordingComplete(blob);
        }
        stream.getTracks().forEach((track) => track.stop());

        // Cleanup AudioContext
        if (audioContextRef.current) {
          audioContextRef.current.close();
          audioContextRef.current = null;
        }
        analyserRef.current = null;
      };

      mediaRecorder.start();
      setIsRecording(true);
      setRecordingTime(0);
      setAudioBlob(null);

      timerRef.current = setInterval(() => {
        setRecordingTime((prev) => prev + 1);
      }, 1000);
    } catch (err) {
      console.error("Error starting recording:", err);
      throw err;
    }
  }, [onRecordingComplete]);

  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    }
  }, [isRecording]);

  return {
    isRecording,
    recordingTime,
    audioBlob,
    startRecording,
    stopRecording,
    analyser: analyserRef.current,
  };
}

export function useVoiceInput({ appendText, onError }: UseVoiceInputOptions) {
  const [isTranscribing, setIsTranscribing] = useState(false);

  const handleRecordingComplete = useCallback(
    async (blob: Blob) => {
      setIsTranscribing(true);
      try {
        const reader = new FileReader();
        reader.readAsDataURL(blob);

        reader.onerror = () => {
          console.error("FileReader error:", reader.error);
          onError?.("Failed to read audio file");
          setIsTranscribing(false);
        };

        reader.onload = async () => {
          try {
            const base64data = reader.result as string | null;
            if (!base64data) {
              onError?.("Failed to convert audio to base64");
              setIsTranscribing(false);
              return;
            }
            const base64Content = base64data.split(",")[1];
            if (!base64Content) {
              onError?.("Invalid audio data format");
              setIsTranscribing(false);
              return;
            }

            const text = await (
              window as unknown as {
                electron: {
                  ipcRenderer: {
                    invoke: (channel: string, data: unknown) => Promise<string>;
                  };
                };
              }
            ).electron.ipcRenderer.invoke("chat:transcribe", {
              audioData: base64Content,
              format: "webm",
            });

            if (text) {
              appendText(text);
            }
          } catch (err) {
            console.error("Transcription failed", err);
            onError?.("Failed to transcribe audio");
          } finally {
            setIsTranscribing(false);
          }
        };
      } catch (err) {
        console.error("Transcription failed", err);
        onError?.("Failed to transcribe audio");
        setIsTranscribing(false);
      }
    },
    [appendText, onError],
  );

  const { isRecording, startRecording, stopRecording, analyser } =
    useAudioRecorder(handleRecordingComplete);

  const handleMicClick = async () => {
    if (isRecording) {
      stopRecording();
    } else {
      try {
        await startRecording();
      } catch (err) {
        console.error("Failed to start recording:", err);
        onError?.("Failed to start recording. Check microphone permissions.");
      }
    }
  };

  return {
    isTranscribing,
    isRecording,
    analyser,
    handleMicClick,
    startRecording,
    stopRecording,
  };
}
